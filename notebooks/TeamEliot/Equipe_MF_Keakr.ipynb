{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mapping dict\n",
    "details = [x for x in range(101)]\n",
    "rating = [1] * 25 + [2] * 25 + [3] * 25 + [4] * 25 + [5] * 25\n",
    "d_map = dict(zip(details, rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/emoll/Downloads/out2.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "# SHAPE : UserID, ItemID, progress, Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['progress'].map(d_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['userID', 'itemID', 'progress', 'Year', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7020071, 5)\n",
      "(3624958, 3)\n",
      "(3624958, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split train and test sets.\n",
    "df_train = df[df.Year < 2022]\n",
    "print(df_train.shape)\n",
    "df_train = df_train.groupby(['userID', 'itemID']).agg({'rating': 'max'}).reset_index()\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = df[df.Year == 2022]\n",
    "df_test = df_test.groupby(['userID', 'itemID']).agg({'rating': 'max'}).reset_index()\n",
    "# Keep only known users in testset\n",
    "df_test = df_test[df_test['userID'].isin(list(set(df_train.userID)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data...\n",
      "fit algo...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1e9bd6532b0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD, SVDpp\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df_train[['userID', 'itemID', 'rating']], reader)\n",
    "print(\"making train/test set...\")\n",
    "trainset, testset = train_test_split(data, test_size=.01) #Lost 1% of data. Solution quick and dirty\n",
    "\n",
    "# Define model\n",
    "algo = SVD()\n",
    "print('fit algo...')\n",
    "# \n",
    "algo.fit(trainset)\n",
    "#cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions to make from events existing in testset\n",
    "preds_to_make = list(zip(df_test.userID, df_test.itemID, df_test.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "outputs = []\n",
    "for user, item, _rating in preds_to_make:\n",
    "    pred = algo.predict(user, item, r_ui=_rating, verbose=False)\n",
    "    \n",
    "    outputs.append((user, item, _rating, pred.est))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute our poorly performing rmse :)\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "realVals = [x[2] for x in outputs]\n",
    "predictedVals = [x[3] for x in outputs]\n",
    "\n",
    "rmse = mean_squared_error(realVals, predictedVals, squared=False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "d = dict(Counter([(x[2], round(x[3])) for x in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33282. 25077.  8185.  2925.   955.]\n",
      " [ 2586.  3405.  1299.   475.   158.]\n",
      " [  683.  1042.   392.   151.    48.]\n",
      " [  461.   682.   305.   128.    46.]\n",
      " [ 3964.  7943.  7522.  6909.  3762.]]\n"
     ]
    }
   ],
   "source": [
    "# Roughly display real and predicted value matrix\n",
    "values = [1, 2, 3, 4, 5]\n",
    "\n",
    "output = np.zeros((len(values), len(values)), dtype=float)\n",
    "for key in d:\n",
    "    i = values.index(key[0])\n",
    "    j = values.index(key[1])\n",
    "    output[i, j] = d[key]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112385.0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40969.0"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.diag(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
